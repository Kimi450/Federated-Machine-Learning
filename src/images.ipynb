{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from user import User\n",
    "from average import Average\n",
    "from tensorflow import keras\n",
    "\n",
    "from graphing import *\n",
    "from file_related import *\n",
    "from inits import *\n",
    "from trainers import *\n",
    "SEED = 0\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# import random\n",
    "# random.seed(SEED)\n",
    "# tf.set_random_seed(SEED)\n",
    "# could need to force keras to not use parallelism, see documentation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.kaggle.com/prasunroy/natural-images\n",
    "data_dir = \"../testing/data/natural_images/\"\n",
    "\n",
    "CLASSES, files = map_images(data_dir)\n",
    "averaging_methods = [Average.all,Average.std_dev,Average.weighted_avg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, toy=False):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        if toy:\n",
    "            epochs=3\n",
    "            steps_per_epoch=20\n",
    "            validation_steps=2\n",
    "        else:\n",
    "            epochs=30\n",
    "#             steps_per_epoch=100\n",
    "            steps_per_epoch=30\n",
    "#             steps_per_epoch=10\n",
    "            validation_steps=5\n",
    "            \n",
    "        # We'll stop training if no improvement after some epochs\n",
    "        earlystopper = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "        # Save the best model during the traning\n",
    "        checkpointer = ModelCheckpoint('best_model1.h5'\n",
    "                                        ,monitor='val_acc'\n",
    "                                        ,verbose=1\n",
    "                                        ,save_best_only=True\n",
    "                                        ,save_weights_only=True)\n",
    "        # Train\n",
    "        training = model.fit(x_train, y_train\n",
    "                                ,epochs=epochs\n",
    "                                ,steps_per_epoch=steps_per_epoch\n",
    "                                ,validation_data=(x_val, y_val)\n",
    "                                ,validation_steps=validation_steps\n",
    "                                ,callbacks=[earlystopper, checkpointer, reduce_lr], verbose=3)\n",
    "        # Get the best saved weights\n",
    "        model.load_weights('best_model1.h5')\n",
    "        return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUNDS = 32 # after about 30-40, it seems to settle down with epochs being 16\n",
    "EPOCHS = 16\n",
    "# MAJORITY_SPLIT = 0.7\n",
    "OUT_PATH = \"../out/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for MAJORITY_SPLIT in [1/8, 0.5, 0.7, 0.99]: #\n",
    "    \n",
    "    print(f\"\\n\\n\\n\\n\\n\\n========={MAJORITY_SPLIT}========\\n\\n\\n\\n\\n\")\n",
    "    # forces tensorfor to the a particular device to run things\n",
    "    #      # return a dictionary of users with data\n",
    "    print(\"Regular\")\n",
    "\n",
    "    users_all = init_users_image(files, averaging_methods, majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_all, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method = Average.all,\n",
    "              averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "\n",
    "\n",
    "    averaging_methods = [Average.std_dev]\n",
    "    # return a dictionary of users with data\n",
    "    print(\"avg - stddev\")\n",
    "\n",
    "    users_std_dev = init_users_image(files, averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_std_dev, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method =  Average.std_dev,\n",
    "             averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "\n",
    "    # return a dictionary of users with data\n",
    "    users_std_dev_p2p = init_users_image(files, averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_std_dev_p2p, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"personalised\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "\n",
    "    averaging_methods = [Average.weighted_avg]\n",
    "    print(\"Weighted\")\n",
    "    # return a dictionary of users with data\n",
    "    users_weighted_avg = init_users_image(files, averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_weighted_avg, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method = Average.weighted_avg,\n",
    "              averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "\n",
    "    # return a dictionary of users with data\n",
    "    users_weighted_avg_p2p = init_users_image(files, averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_weighted_avg_p2p, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"personalised\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "    print(\"Local only\")\n",
    "    users_local_only = init_users_image(files, averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED)\n",
    "    train_fed(users = users_local_only, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "\n",
    "              strat = \"local_trainings_only\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_metric = \"accuracy\")\n",
    "\n",
    "    print(\"Global\")\n",
    "\n",
    "    global_user = init_users_image(files,averaging_methods,majority_split = MAJORITY_SPLIT, seed = SEED, return_global_user=True)\n",
    "    # print(global_user.get_train_data().dtype)\n",
    "    # global_user.get_model().summary()\n",
    "    global_user.train(\n",
    "        epochs = ROUNDS*EPOCHS,\n",
    "        verbose_fit = False,\n",
    "        verbose_evaluate = False\n",
    "    )\n",
    "\n",
    "    ignore_first_n = 0\n",
    "    final_values = False\n",
    "    for GRAPHING_METRIC in [\"accuracy\", \"loss\"]:\n",
    "        round_summary_df = pd.DataFrame(columns=['Strategy','Position', 'Round', 'Average', 'Standard Deviation', 'Minimum', 'Maximum'])\n",
    "        user_summary_df = pd.DataFrame(columns=['Strategy', 'Position', 'User', 'Average', 'Standard Deviation', 'Minimum', 'Maximum', 'Final Value'])\n",
    "        print(\"All\")\n",
    "\n",
    "        print(\"For central\")\n",
    "\n",
    "\n",
    "        df_avg_round_stats_acc = avg_round_stats(users_all, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"centralround-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_all, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"centraluser-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"centralround\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"centraluser\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "        print(\"Std deviation\")\n",
    "        print(\"For central\")\n",
    "\n",
    "\n",
    "        df_avg_round_stats_acc = avg_round_stats(users_std_dev, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"stdround-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_std_dev, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"stduser-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"stdround\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"stduser\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "        \n",
    "        print(\"For p2p\")\n",
    "        \n",
    "        df_avg_round_stats_acc = avg_round_stats(users_std_dev_p2p, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"stdround_p2p-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_std_dev_p2p, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"stduser_p2p-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"stdround_p2p\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"stduser_p2p\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        print(\"Weighted average\")\n",
    "\n",
    "        print(\"For central\")\n",
    "\n",
    "\n",
    "        df_avg_round_stats_acc = avg_round_stats(users_weighted_avg, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"weightround-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_weighted_avg, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"weightuser-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"weightround\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"weightuser\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "\n",
    "        print(\"For p2p\")\n",
    "\n",
    "\n",
    "        df_avg_round_stats_acc = avg_round_stats(users_weighted_avg_p2p, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"weightround_p2p-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_weighted_avg_p2p, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"weightuser_p2p-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"weightround_p2p\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"weightuser_p2p\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        print(\"Local training only\")\n",
    "\n",
    "\n",
    "        df_avg_round_stats_acc = avg_round_stats(users_local_only, \n",
    "                                                 ignore_first_n = ignore_first_n, \n",
    "                                                 min_max_fill = True, \n",
    "                                                 metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"localround-{MAJORITY_SPLIT}\",\n",
    "                                                 final_values = final_values)\n",
    "        df_avg_user_stats_acc = avg_user_stats(users_local_only, \n",
    "                                               ignore_first_n = ignore_first_n, \n",
    "                                               min_max_fill = True, \n",
    "                                               metric = GRAPHING_METRIC, path= OUT_PATH, save_as = f\"localuser-{MAJORITY_SPLIT}\",\n",
    "                                               final_values = final_values)\n",
    "        # draw_graphs(users_all_p2p[2])\n",
    "        last_2 = df_avg_round_stats_acc[-2:]\n",
    "        last_2[\"Strategy\"] = \"localround\"\n",
    "        round_summary_df = round_summary_df.append(last_2).reset_index(drop=True)\n",
    "        df_avg_user_stats_acc[\"Strategy\"] = \"localuser\"\n",
    "        user_summary_df = user_summary_df.append(df_avg_user_stats_acc).reset_index(drop=True)\n",
    "\n",
    "        print(round_summary_df)\n",
    "        round_summary_df.to_csv(os.path.join(OUT_PATH,f'summary-rounds-{GRAPHING_METRIC}-{MAJORITY_SPLIT}.csv')) \n",
    "        user_summary_df.to_csv(os.path.join(OUT_PATH,f'summary-users-{GRAPHING_METRIC}-{MAJORITY_SPLIT}.csv')) \n",
    "\n",
    "        draw_graphs(global_user, path= OUT_PATH, save_as=f\"global_{MAJORITY_SPLIT}\")\n",
    "\n",
    "        with open(f\"{OUT_PATH}{GRAPHING_METRIC}-{MAJORITY_SPLIT}.csv\", \"w\") as out:\n",
    "            strats = [users_local_only, users_all, users_std_dev, users_std_dev_p2p, users_weighted_avg, users_weighted_avg_p2p]\n",
    "            strats_names = [\"Local only\", \"All (traditional)\", \"Std dev Central\", \"Std dev P2P\", \"Weighted avg Central\", \"Weighted avg P2P\"]\n",
    "            g_weights = global_user.get_weights()\n",
    "            out.write(\"Testing user models (post fit) on global model aggregate data,\\n\")\n",
    "            e = global_user.evaluate(verbose=False)\n",
    "            out.write(f\"{GRAPHING_METRIC}-globaluser,{e[0]},{e[1]},\\n\")\n",
    "        #     print(global_user.evaluate(verbose=False))\n",
    "\n",
    "            for i, strat in enumerate(strats):\n",
    "        #         print(strats_names[i])\n",
    "                out.write(strats_names[i]+\",\\n\")\n",
    "                for user in strat.values():\n",
    "                    global_user.set_weights(user.get_weights())\n",
    "                    e = global_user.evaluate(verbose=False)\n",
    "                    out.write(f\"{GRAPHING_METRIC}-user-{user.get_id()}:,{e[0]},{e[1]},\\n\")\n",
    "        #             print(f\"{GRAPHING_METRIC}-{user.get_id()}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user = users_local_only[4]\n",
    "# for i, user in enumerate(users_all.values()):\n",
    "#     print(f\"{GRAPHING_METRIC}-{CLASSES[i]:<10} -> {user.get_id()}: {np.unique(user.get_train_class(), return_counts=True)}\")\n",
    "    \n",
    "# print(f\"{GRAPHING_METRIC}-{' ':<10} -> {global_user.get_id()}: {np.unique(global_user.get_train_class(), return_counts=True)}\")\n",
    "# print(f\"{GRAPHING_METRIC}-{' ':<10} -> {global_user.get_id()}: {np.unique(global_user.get_test_class(), return_counts=True)}\")\n",
    "# print(f\"{GRAPHING_METRIC}-{' ':<10} -> {global_user.get_id()}: {np.unique(global_user.get_val_class(), return_counts=True)}\")\n",
    "\n",
    "# # print(np.equal(users_all[1].get_test_class(),users_weighted_avg[1].get_test_class()).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_user_stats_acc.columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
