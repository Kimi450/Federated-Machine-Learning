{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from user import User\n",
    "from average import Average\n",
    "from graphing import *\n",
    "from file_related import *\n",
    "from inits import *\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "from six.moves import range\n",
    "import six\n",
    "\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'It works!'\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# import random\n",
    "# random.seed(SEED)\n",
    "# tf.set_random_seed(SEED)\n",
    "# could need to force keras to not use parallelism, see documentation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#@test {\"skip\": true}\n",
    "\n",
    "# NOTE: If you are running a Jupyter notebook, and installing a locally built\n",
    "# pip package, you may need to edit the following to point to the '.whl' file\n",
    "# on your local filesystem.\n",
    "\n",
    "# NOTE: The high-performance executor components used in this tutorial are not\n",
    "# yet included in the released pip package; you may need to compile from source.\n",
    "\n",
    "# NOTE: Jupyter requires a patch to asyncio.\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# NOTE: If the statement below fails, it means that you are\n",
    "# using an older version of TFF without the high-performance\n",
    "# executor stack. Call `tff.framework.set_default_executor()`\n",
    "# instead to use the default reference runtime.\n",
    "if six.PY3:\n",
    "    tff.framework.set_default_executor(tff.framework.create_local_executor())\n",
    "\n",
    "print(tff.federated_computation(lambda: 'It works!')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_federated.python.simulation import hdf5_client_data\n",
    "# https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/simulation/hdf5_client_data_test.py\n",
    "# https://github.com/tensorflow/federated/blob/v0.11.0/tensorflow_federated/python/simulation/hdf5_client_data.py\n",
    "# http://docs.h5py.org/en/stable/high/group.html#Group.create_dataset\n",
    "# https://stackoverflow.com/questions/55434004/create-a-custom-federated-data-set-in-tensorflow-federated\n",
    "# https://stackoverflow.com/questions/58965488/how-to-create-federated-dataset-from-a-csv-file\n",
    "\n",
    "file = \"dataset.hdf5\"\n",
    "\n",
    "df = read_file(\"../dataset/allUsers.lcl.csv\")\n",
    "NUM_CLIENTS = create_hdf5(df,file,0)\n",
    "\n",
    "train = hdf5_client_data.HDF5ClientData(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " <BatchDataset shapes: OrderedDict([(x, (None, 36)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.float32)])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 16\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 0\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "    def element_fn(element):\n",
    "        return collections.OrderedDict([\n",
    "            ('x', tf.reshape(element['points'], [-1])),\n",
    "            ('y', tf.reshape(element['label'], [1])),\n",
    "        ])\n",
    "    return dataset.repeat(NUM_EPOCHS).map(element_fn).batch(BATCH_SIZE)\n",
    "#     return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(\n",
    "#       SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "def make_federated_data(client_data, client_ids):\n",
    "    return [preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "          for x in client_ids]\n",
    "\n",
    "def model_fn():\n",
    "    keras_model = init_model()\n",
    "    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)\n",
    "\n",
    "sample_clients = train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(train, sample_clients)\n",
    "\n",
    "len(federated_train_data), federated_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 72.05118    12.736734  -71.69564    70.23323   -12.197811  -59.39264\n",
      "  54.848625  -40.39899   -47.726048   26.460789   34.228977  -74.096954\n",
      "   4.3407264  44.69395   -70.86358     0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_dataset = train.create_tf_dataset_for_client(\n",
    "    train.client_ids[11])\n",
    "\n",
    "example_element = iter(example_dataset).next()\n",
    "\n",
    "print(example_element['points'].numpy())\n",
    "print(example_element[\"label\"].numpy())\n",
    "\n",
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "sample_batch = tf.nest.map_structure(\n",
    "    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n",
    "# type(train)\n",
    "# print(sample_batch[\"y\"])\n",
    "\n",
    "# print(sample_batch[\"x\"].shape)\n",
    "# print(sample_batch[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kts1/proj/env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kts1/proj/env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <model=<trainable=<sequential/dense/kernel=float32[36,32],sequential/dense/bias=float32[32],sequential/dense_1/kernel=float32[32,6],sequential/dense_1/bias=float32[6]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)\n",
    "print(str(iterative_process.initialize.type_signature))\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=<sparse_categorical_accuracy=0.8757650852203369,loss=0.8561046719551086>\n",
      "round  1, metrics=<sparse_categorical_accuracy=0.9087525010108948,loss=0.35225701332092285>\n",
      "round  2, metrics=<sparse_categorical_accuracy=0.931107223033905,loss=0.27405238151550293>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.9360874891281128,loss=0.272421270608902>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.9386147856712341,loss=0.24905142188072205>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.9421496987342834,loss=0.25311222672462463>\n",
      "round  6, metrics=<sparse_categorical_accuracy=0.9441064596176147,loss=0.22794567048549652>\n",
      "round  7, metrics=<sparse_categorical_accuracy=0.9441776871681213,loss=0.23617136478424072>\n",
      "round  8, metrics=<sparse_categorical_accuracy=0.947548508644104,loss=0.22174479067325592>\n",
      "round  9, metrics=<sparse_categorical_accuracy=0.9474636912345886,loss=0.2141287624835968>\n",
      "round 10, metrics=<sparse_categorical_accuracy=0.9430468678474426,loss=0.22137902677059174>\n",
      "round 11, metrics=<sparse_categorical_accuracy=0.9458407163619995,loss=0.21781933307647705>\n",
      "round 12, metrics=<sparse_categorical_accuracy=0.9463136792182922,loss=0.2203228622674942>\n",
      "round 13, metrics=<sparse_categorical_accuracy=0.9476333856582642,loss=0.21430441737174988>\n",
      "round 14, metrics=<sparse_categorical_accuracy=0.9502103328704834,loss=0.20703129470348358>\n",
      "round 15, metrics=<sparse_categorical_accuracy=0.9521478414535522,loss=0.20686207711696625>\n",
      "round 16, metrics=<sparse_categorical_accuracy=0.9541333913803101,loss=0.19949041306972504>\n",
      "round 17, metrics=<sparse_categorical_accuracy=0.9540965557098389,loss=0.19994358718395233>\n",
      "round 18, metrics=<sparse_categorical_accuracy=0.9524935483932495,loss=0.20772387087345123>\n",
      "round 19, metrics=<sparse_categorical_accuracy=0.9537116289138794,loss=0.2080908566713333>\n",
      "round 20, metrics=<sparse_categorical_accuracy=0.9520285725593567,loss=0.21341051161289215>\n",
      "round 21, metrics=<sparse_categorical_accuracy=0.9526520371437073,loss=0.22028633952140808>\n",
      "round 22, metrics=<sparse_categorical_accuracy=0.9513835310935974,loss=0.21195285022258759>\n",
      "round 23, metrics=<sparse_categorical_accuracy=0.9530962109565735,loss=0.20897531509399414>\n",
      "round 24, metrics=<sparse_categorical_accuracy=0.954396665096283,loss=0.20602847635746002>\n",
      "round 25, metrics=<sparse_categorical_accuracy=0.9557315707206726,loss=0.19434234499931335>\n",
      "round 26, metrics=<sparse_categorical_accuracy=0.9544310569763184,loss=0.19992844760417938>\n",
      "round 27, metrics=<sparse_categorical_accuracy=0.9568215608596802,loss=0.190176323056221>\n",
      "round 28, metrics=<sparse_categorical_accuracy=0.9564342498779297,loss=0.20357877016067505>\n",
      "round 29, metrics=<sparse_categorical_accuracy=0.9571937322616577,loss=0.20042088627815247>\n",
      "round 30, metrics=<sparse_categorical_accuracy=0.9580259919166565,loss=0.19942112267017365>\n",
      "round 31, metrics=<sparse_categorical_accuracy=0.9559908509254456,loss=0.20159119367599487>\n",
      "round 32, metrics=<sparse_categorical_accuracy=0.9598827362060547,loss=0.1923208385705948>\n",
      "round 33, metrics=<sparse_categorical_accuracy=0.9607238173484802,loss=0.19847995042800903>\n",
      "round 34, metrics=<sparse_categorical_accuracy=0.9592961072921753,loss=0.20172224938869476>\n",
      "round 35, metrics=<sparse_categorical_accuracy=0.9546191692352295,loss=0.20846930146217346>\n",
      "round 36, metrics=<sparse_categorical_accuracy=0.9567839503288269,loss=0.19958285987377167>\n",
      "round 37, metrics=<sparse_categorical_accuracy=0.9553074240684509,loss=0.20120058953762054>\n",
      "round 38, metrics=<sparse_categorical_accuracy=0.957537829875946,loss=0.1944625824689865>\n",
      "round 39, metrics=<sparse_categorical_accuracy=0.9568591713905334,loss=0.19822916388511658>\n",
      "round 40, metrics=<sparse_categorical_accuracy=0.9567815661430359,loss=0.2010055035352707>\n",
      "round 41, metrics=<sparse_categorical_accuracy=0.956579864025116,loss=0.1978980153799057>\n",
      "round 42, metrics=<sparse_categorical_accuracy=0.956875205039978,loss=0.19687312841415405>\n",
      "round 43, metrics=<sparse_categorical_accuracy=0.957229733467102,loss=0.19620458781719208>\n",
      "round 44, metrics=<sparse_categorical_accuracy=0.9570664763450623,loss=0.20040030777454376>\n",
      "round 45, metrics=<sparse_categorical_accuracy=0.9569023847579956,loss=0.20185527205467224>\n",
      "round 46, metrics=<sparse_categorical_accuracy=0.9572977423667908,loss=0.2061627209186554>\n",
      "round 47, metrics=<sparse_categorical_accuracy=0.9591560363769531,loss=0.20463943481445312>\n",
      "round 48, metrics=<sparse_categorical_accuracy=0.9559964537620544,loss=0.21172913908958435>\n",
      "round 49, metrics=<sparse_categorical_accuracy=0.9553754329681396,loss=0.21189668774604797>\n",
      "round 50, metrics=<sparse_categorical_accuracy=0.9570608735084534,loss=0.2086322009563446>\n",
      "round 51, metrics=<sparse_categorical_accuracy=0.9572921395301819,loss=0.20914913713932037>\n",
      "round 52, metrics=<sparse_categorical_accuracy=0.958452582359314,loss=0.20243625342845917>\n",
      "round 53, metrics=<sparse_categorical_accuracy=0.9557875990867615,loss=0.20544841885566711>\n",
      "round 54, metrics=<sparse_categorical_accuracy=0.9515340328216553,loss=0.21239817142486572>\n",
      "round 55, metrics=<sparse_categorical_accuracy=0.9516180157661438,loss=0.21234475076198578>\n",
      "round 56, metrics=<sparse_categorical_accuracy=0.9537428021430969,loss=0.20793379843235016>\n",
      "round 57, metrics=<sparse_categorical_accuracy=0.9533330798149109,loss=0.21032361686229706>\n",
      "round 58, metrics=<sparse_categorical_accuracy=0.9535667896270752,loss=0.20994795858860016>\n",
      "round 59, metrics=<sparse_categorical_accuracy=0.9466665983200073,loss=0.2233535796403885>\n",
      "round 60, metrics=<sparse_categorical_accuracy=0.9472748041152954,loss=0.21536535024642944>\n",
      "round 61, metrics=<sparse_categorical_accuracy=0.9479294419288635,loss=0.21270926296710968>\n",
      "round 62, metrics=<sparse_categorical_accuracy=0.9491747617721558,loss=0.21200025081634521>\n",
      "round 63, metrics=<sparse_categorical_accuracy=0.9493948221206665,loss=0.21074175834655762>\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  0, metrics={}'.format(metrics))\n",
    "NUM_ROUNDS = 64\n",
    "for round_num in range(1, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<trainable=<sequential/dense/kernel=float32[36,32],sequential/dense/bias=float32[32],sequential/dense_1/kernel=float32[32,6],sequential/dense_1/bias=float32[6]>,non_trainable=<>>@SERVER,{<x=float32[?,36],y=float32[?,1]>*}@CLIENTS> -> <sparse_categorical_accuracy=float32@SERVER,loss=float32@SERVER>)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(evaluation.type_signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sparse_categorical_accuracy=0.7196143269538879,loss=1.8806164264678955>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics = evaluation(state.model, federated_train_data)\n",
    "str(train_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
