{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from user import User\n",
    "from average import Average\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# import random\n",
    "# random.seed(SEED)\n",
    "# tf.set_random_seed(SEED)\n",
    "# could need to force keras to not use parallelism, see documentation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_file(file):\n",
    "    \"\"\"\n",
    "    return 2d df after imputing with 0s\"\"\"\n",
    "\n",
    "    # read data\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # replace the question marks with NaN and then change data type to float 32\n",
    "    df.replace([\"?\"],np.nan, inplace = True)\n",
    "    df = df.astype(np.float32)\n",
    "\n",
    "    # imputation\n",
    "    df.fillna(0,inplace=True) # fill nulls with 0\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_dataframe(df, for_user = None, val_size = 0.25, test_size =  0.75, seed = None):\n",
    "    \"\"\"\n",
    "    split the dataframe into train, validation and test splits based on the same seed\n",
    "    \"\"\"\n",
    "    # split into train, validation and test data using sklearn and return dfs for each\n",
    "    if for_user!=None:\n",
    "        df = df[df[\"User\"] == for_user]\n",
    "    if df.shape[0] == 0:\n",
    "        # if no data for the user, then return 9 empty dfs as per the api\n",
    "        # print(f\"Dataframe for user {user} is of shape {df.shape}, no data. Skipping...\")\n",
    "        df = pd.DataFrame()\n",
    "        return (df for _ in range(9))\n",
    "    df_train, df_test = train_test_split(df,\n",
    "                                         test_size = test_size,\n",
    "                                         random_state = seed)\n",
    "\n",
    "    df_train, df_val  = train_test_split(df_train,\n",
    "                                         test_size = val_size,\n",
    "                                         random_state = seed)\n",
    "\n",
    "    # store class and user information (in order)\n",
    "    df_val_class, df_train_class, df_test_class = df_val[\"Class\"], df_train[\"Class\"], df_test[\"Class\"]\n",
    "    df_val_user,  df_train_user,  df_test_user  = df_val[\"User\"],  df_train[\"User\"],  df_test[\"User\"]\n",
    "\n",
    "    # drop the class and user identifier columns from data frame\n",
    "    df_val   = df_val.  drop(df_train.columns[[0,1]], axis=1)\n",
    "    df_train = df_train.drop(df_train.columns[[0,1]], axis=1)\n",
    "    df_test  = df_test. drop(df_test. columns[[0,1]], axis=1)\n",
    "\n",
    "    return df_val, df_val_class,  df_val_user,\\\n",
    "        df_test, df_test_class, df_test_user, \\\n",
    "        df_train, df_train_class, df_train_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def init_model(init_seed=None):\n",
    "    \"\"\"\n",
    "    initialise and return a model \n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "#         keras.layers.Dense(4096, activation='relu',\n",
    "#             kernel_initializer=keras.initializers.glorot_uniform(seed=init_seed)),\n",
    "#         keras.layers.Dense(1024, activation='relu',\n",
    "#             kernel_initializer=keras.initializers.glorot_uniform(seed=init_seed)),\n",
    "        keras.layers.Dense(128, activation='relu',\n",
    "            kernel_initializer=keras.initializers.glorot_uniform(seed=init_seed)),\n",
    "        keras.layers.Dense(32, activation='relu',\n",
    "            kernel_initializer=keras.initializers.glorot_uniform(seed=init_seed)),\n",
    "        keras.layers.Dense(6, activation='softmax',\n",
    "            kernel_initializer=keras.initializers.glorot_uniform(seed=init_seed))\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "def init_users(df, averaging_method, avg_metric_loss = False, avg_metric_acc = True, seed = None):\n",
    "    \"\"\"\n",
    "    initialise users based on dataframe given and assign random averaging method\n",
    "    to them based on the list passed in.\n",
    "    returns a dictionary of users(key: user object) and a global user object\n",
    "    \"\"\"    \n",
    "    print(\"Initialising User instances...\")\n",
    "    users = dict()\n",
    "    num_users = df[\"User\"].nunique()\n",
    "\n",
    "    for user_id in range(-1,num_users):\n",
    "\n",
    "        i = user_id\n",
    "\n",
    "        if user_id < 0: # for global user with id -1\n",
    "            user_id = None\n",
    "\n",
    "        df_val, df_val_class,  df_val_user,\\\n",
    "        df_test, df_test_class, df_test_user,\\\n",
    "        df_train, df_train_class, df_train_user = split_dataframe(df, for_user=user_id, seed = seed)\n",
    "\n",
    "        user_id = i\n",
    "\n",
    "        if df_train.shape[0]==0:\n",
    "            print(f\"User {user_id} has no data, no instance created...\")\n",
    "            continue\n",
    "\n",
    "        model = init_model(init_seed = seed)\n",
    "        \n",
    "# \n",
    "        option = np.random.randint(0,len(averaging_methods))\n",
    "#         avg_metric_loss = False\n",
    "#         avg_metric_acc = True\n",
    "#         if option==2:\n",
    "#             avg_metric_loss = not avg_metric_loss\n",
    "#             avg_metric_acc = not avg_metric_acc\n",
    "        users[user_id] = User(user_id=user_id,\n",
    "                          model = model,\n",
    "                          averaging_method = averaging_methods[option],\n",
    "                          averaging_metric_loss = avg_metric_loss,\n",
    "                          averaging_metric_accuracy = avg_metric_acc,\n",
    "                          train_class = df_train_class,\n",
    "                          train_data = df_train,\n",
    "                          val_class = df_val_class,\n",
    "                          val_data = df_val,\n",
    "                          test_class = df_test_class,\n",
    "                          test_data = df_test)\n",
    "\n",
    "    global_user = users.pop(-1)\n",
    "    global_user.set_averaging_method(averaging_methods[0])\n",
    "    print(f\"{len(users.keys())} User instances and a global user created!\")\n",
    "    return users, global_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_users(users, epochs,\n",
    "                new_weights = None,\n",
    "                train_user_verbose_evaluate = 0,\n",
    "                train_user_verbose_fit = False,\n",
    "                verbose = True):\n",
    "    \"\"\"\n",
    "    this method is used to train all users on the passed in epochs value\n",
    "    \"\"\"\n",
    "    \n",
    "    for user in users.values():\n",
    "        # if user.get_id() < 0:\n",
    "        #     continue\n",
    "\n",
    "        if verbose:\n",
    "            message = f\"User {user.get_id()} being trained on the model...\"\n",
    "            print(message)\n",
    "\n",
    "        user.train(\n",
    "            epochs = epochs,\n",
    "            weights = new_weights, # if none, then wont be updated\n",
    "            verbose_fit = train_user_verbose_fit,\n",
    "            verbose_evaluate = train_user_verbose_evaluate\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            message = f\"User {user.get_id()} done!\"\n",
    "            print(message)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def train_fed(epochs, rounds, users,\n",
    "              verbose = True,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method = Average.all,\n",
    "             averaging_pre = False,\n",
    "             averaging_post = False,\n",
    "             averaging_loss = False,\n",
    "             averaging_accuracy = False):\n",
    "    \"\"\"\n",
    "    this function trains a federation of users using 'strat' stratergy\n",
    "    central or personalised\n",
    "    \n",
    "    central is where all the users send data to a server and the server\n",
    "    sends back new weights\n",
    "    \n",
    "    personalised is where all the users are sent each others data\n",
    "    and the user tests how their own test data performs on everyone \n",
    "    elses models. Based on their policy, they then decide what way\n",
    "    to average the data.\n",
    "    \"\"\"\n",
    "\n",
    "    new_weights = None\n",
    "    for i in range(rounds):\n",
    "        # users' weights will not be updated till round i+1\n",
    "        if verbose:\n",
    "            message = f\"{'*'*32} {i:^4} {'*'*32}\"\n",
    "            print(message)\n",
    "\n",
    "        train_users(users, epochs = EPOCHS,\n",
    "                   new_weights = new_weights,\n",
    "                   verbose = train_user_verbose,\n",
    "                   train_user_verbose_evaluate = train_user_verbose_evaluate,\n",
    "                   train_user_verbose_fit = train_user_verbose_fit)\n",
    "        if strat == \"central\":\n",
    "            # calc new weight and pass it to train users \n",
    "            # in next round for the users to update their\n",
    "            # model and retrain on their local train data\n",
    "            new_weights = averaging_method(users, \n",
    "                                  pre = averaging_pre,\n",
    "                                  post = averaging_post, \n",
    "                                  accuracy = averaging_accuracy, \n",
    "                                  loss = averaging_loss)\n",
    "    \n",
    "        elif strat == \"personalised\":\n",
    "            new_weights = dict()\n",
    "            for user in users.values():\n",
    "                # gather everyones models/weights in a dict\n",
    "                # and pass it to train users in next round\n",
    "                new_weights[user.get_id()] = user.get_weights()\n",
    "            \n",
    "        if verbose:\n",
    "            message = f\"{'*'*32} {'DONE':^4} {'*'*32}\"\n",
    "            print(message)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def draw_graphs(user, loss = True, accuracy = True):\n",
    "    # this is from the book 74,75\n",
    "    # history = model.fit(...)\n",
    "    \"\"\"\n",
    "    this function draws the history graph for the user from the most\n",
    "    recent fit performed on it\n",
    "    \"\"\"\n",
    "\n",
    "    history = user.get_history()\n",
    "    history_dict = history.history\n",
    "\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    acc_values = history_dict['acc']\n",
    "    val_acc_values = history_dict['val_acc']\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.xlabel('Epochs')\n",
    "\n",
    "    if loss:\n",
    "        plt.plot(epochs, acc_values, 'b', label='Training acc')\n",
    "        plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    if accuracy:\n",
    "        plt.plot(epochs, loss_values, 'b', label='Training loss')\n",
    "        plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "def _plot_with_fill(df, x_axis, position, metric, color, std_dev_fill, min_max_fill):\n",
    "    \"\"\"\n",
    "    private function used to plot the average line and provide a fill\n",
    "    based on the fill strategy passed in\n",
    "    \"\"\"\n",
    "\n",
    "    position_label = f\"{position}-fit\"\n",
    "    position_df = df[df[\"Position\"]==f\"{position}\"]\n",
    "    avg = position_df[\"Average\"]\n",
    "    plt.plot(x_axis, avg, color, linewidth = 1, label = f\"{position_label} {metric}\")\n",
    "\n",
    "    if std_dev_fill:\n",
    "        std_dev = position_df[\"Standard Deviation\"]\n",
    "        plt.fill_between(x_axis, \n",
    "                         avg - std_dev, \n",
    "                         avg + std_dev, \n",
    "                         alpha=0.08, color = color)\n",
    "    elif min_max_fill:\n",
    "        mini = position_df[\"Minimum\"]\n",
    "        maxi = position_df[\"Maximum\"]\n",
    "        plt.fill_between(x_axis,\n",
    "                         maxi, \n",
    "                         avg, \n",
    "                         alpha=0.08, color = color)\n",
    "        plt.fill_between(x_axis,\n",
    "                         avg, \n",
    "                         mini, \n",
    "                             alpha=0.08, color = color)\n",
    "\n",
    "def _userwise_data(user, \n",
    "                     ignore_first_n = 0, \n",
    "                      loss = False, \n",
    "                      accuracy = False, \n",
    "                      post = False, pre = False):\n",
    "    \"\"\"\n",
    "    private function used to provide average, std_dev, min, max and final values\n",
    "    of the defined metric and position which are passed in\n",
    "    \"\"\"\n",
    "\n",
    "    user_data = user.get_data(ignore_first_n = ignore_first_n, \n",
    "                                      loss = loss, \n",
    "                                      accuracy = accuracy, \n",
    "                                      pre= pre,\n",
    "                                     post = post)\n",
    "    avg = np.average(user_data)\n",
    "    std_dev = np.std(user_data)\n",
    "    mini = np.amin(user_data)\n",
    "    maxi = np.amax(user_data)\n",
    "    final = user_data[-1]\n",
    "    return (user_data,avg, std_dev, mini, maxi,final)        \n",
    "\n",
    "def userwise_stats_df(users,ignore_first_n = 0, \n",
    "                      loss = False, \n",
    "                      accuracy = False, \n",
    "                      post = False, pre = False):\n",
    "    \"\"\"\n",
    "    returns a dataframe of data obtained from userwise_data based on position and metrics with\n",
    "    cols [\"Position\", \"User\", \"Average\", \"Standard Deviation\", \"Minimum\", \"Maximum\", \"Final Value\"]\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [\"Position\", \"User\", \"Average\", \"Standard Deviation\", \"Minimum\", \"Maximum\", \"Final Value\"]\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    df_index = 0    \n",
    "    for i, user in users.items():\n",
    "        if post:\n",
    "            user_data,avg, std_dev, mini, maxi,final = \\\n",
    "              _userwise_data(user, \n",
    "                ignore_first_n = ignore_first_n, \n",
    "                loss = loss, \n",
    "                accuracy = accuracy, \n",
    "                post = post)\n",
    "\n",
    "            df.loc[df_index] = [\"Post\", i, avg, std_dev, mini, maxi, final]\n",
    "            df_index +=1\n",
    "        if pre:\n",
    "            user_data,avg, std_dev, mini, maxi,final = \\\n",
    "                   _userwise_data(user, \n",
    "                     ignore_first_n = ignore_first_n, \n",
    "                          loss = loss, \n",
    "                          accuracy = accuracy, \n",
    "                          pre = pre)       \n",
    "            df.loc[df_index] = [\"Pre\", i, avg, std_dev, mini, maxi, final]\n",
    "\n",
    "            df_index +=1 \n",
    "    return df\n",
    "\n",
    "def avg_user_stats(users, std_dev_fill = False, min_max_fill = False,\n",
    "                        loss = False, accuracy = False, pre = True, post = True,\n",
    "                        ignore_first_n = 0, save_as = None, final_values = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    prints graphs based on per user data and optionally returns the final metric \n",
    "    values for them as well. Use save_as to save the graph plotted and can ignore_first_n\n",
    "    round data in the graphin\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if (loss == accuracy) or (std_dev_fill and min_max_fill):\n",
    "        print(\"Please select one from accuracy or loss and one or nonefrom std_dev_fill or min_max_fill\")\n",
    "        return None\n",
    "    # get the data for the prints ready\n",
    "    metric = \"Accuracy\"\n",
    "    if loss:\n",
    "        metric = \"Loss\"\n",
    "    \n",
    "    fill_type = None\n",
    "    if std_dev_fill:\n",
    "        fill_type = \"std_dev_fill\"\n",
    "    elif min_max_fill:\n",
    "        fill_type = \"min_max_fill\"\n",
    "    \n",
    "    \n",
    "    # data collection into df\n",
    "    df = userwise_stats_df(users, \n",
    "                     ignore_first_n = ignore_first_n, \n",
    "                          loss = loss, \n",
    "                          accuracy = accuracy, \n",
    "                        post = post , pre = pre)\n",
    "            \n",
    "    user_ids = list(users.keys())\n",
    "    # plot here and then fill here\n",
    "    \n",
    "    if pre:\n",
    "        if final_values:\n",
    "            _print_finals(df, position = \"Pre\", metric= metric)\n",
    "            \n",
    "        _plot_with_fill(df, x_axis = user_ids,\n",
    "                        position = \"Pre\",\n",
    "                        metric = metric,\n",
    "                        color = \"r\",\n",
    "                        min_max_fill = min_max_fill, \n",
    "                        std_dev_fill = std_dev_fill)\n",
    "    \n",
    "    if post:\n",
    "        if final_values:\n",
    "            _print_finals(df, position = \"Post\", metric = metric)\n",
    "        \n",
    "        _plot_with_fill(df, x_axis = user_ids,\n",
    "                        position = \"Post\",\n",
    "                        metric = metric,\n",
    "                        color = \"b\",\n",
    "                        min_max_fill = min_max_fill, \n",
    "                        std_dev_fill = std_dev_fill)\n",
    "\n",
    "    \n",
    "    plt.xlabel(\"Users\")\n",
    "    plt.ylabel(f\"{metric}\")\n",
    "    plt.title(f\"Average {metric} per User with fill type: {fill_type}\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if save_as:\n",
    "        plt.savefig(save_as)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _print_finals(df, position, metric):\n",
    "    \"\"\"\n",
    "    prints the final averaged value for metric and position defined\n",
    "    \"\"\"\n",
    "    finals =df[df[\"Position\"]==f\"{position}\"]\n",
    "    finals = finals[[\"User\", \"Final Value\"]]\n",
    "    print(f\"Final {metric} for {position}-fit data\")\n",
    "    print(finals)\n",
    "    print(f\"Averaged: {finals['Final Value'].mean()}\\n\")\n",
    "\n",
    "\n",
    "def _roundwise_data(users, \n",
    "                     ignore_first_n = 0, \n",
    "                      loss = False, \n",
    "                      accuracy = False, \n",
    "                      post = False, pre = False):\n",
    "    \"\"\"\n",
    "    returns a tuple of data for based on rounds containing all data, rounds, \n",
    "    average, standard deviation, min value and max value per \n",
    "    \"\"\"\n",
    "    user_data = []\n",
    "    for i, user in users.items():\n",
    "        user_data_temp = user.get_data(ignore_first_n = ignore_first_n, \n",
    "                                  loss = loss, \n",
    "                                  accuracy = accuracy, \n",
    "                                  post = post, pre = pre)\n",
    "        user_data.append(user_data_temp)\n",
    "    user_data = np.asarray(user_data)\n",
    "    rounds = len(user_data[0])\n",
    "    avg = np.average(user_data, axis = 0)\n",
    "    std_dev = np.std(user_data,  axis = 0)\n",
    "    mini = np.amin(user_data, axis = 0)\n",
    "    maxi = np.amax(user_data, axis = 0)\n",
    "    return (user_data,rounds,avg, std_dev, mini, maxi)        \n",
    "\n",
    "def roundwise_stats_df(users,ignore_first_n = 0, \n",
    "                      loss = False, \n",
    "                      accuracy = False, \n",
    "                      post = False, pre = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns a data frame of the cols\n",
    "    [\"Position\", \"Round\", \"Average\", \"Standard Deviation\", \"Minimum\", \"Maximum\"]\n",
    "    based on data recieved from roundwise_data catered to position and metric passed in\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [\"Position\", \"Round\", \"Average\", \"Standard Deviation\", \"Minimum\", \"Maximum\"]\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "        \n",
    "    # collect user metric values into a numpy array\n",
    "    # of shape (number of users, number of rounds)\n",
    "    # and calculate roundwise average across all users returning an\n",
    "    # array for the average of the round across all users\n",
    "    if post:\n",
    "        user_data_post,rounds,post_avg, post_std_dev, post_mini, post_maxi = \\\n",
    "                          _roundwise_data(users,\n",
    "                          ignore_first_n = ignore_first_n, \n",
    "                          loss = loss, \n",
    "                          accuracy = accuracy, \n",
    "                          post = post)\n",
    "    if pre:\n",
    "        user_data_pre,rounds,pre_avg, pre_std_dev, pre_mini, pre_maxi = \\\n",
    "                          _roundwise_data(users,\n",
    "                          ignore_first_n = ignore_first_n, \n",
    "                          loss = loss, \n",
    "                          accuracy = accuracy, \n",
    "                          pre = pre)\n",
    "        \n",
    "    # the arrays consisting of averages for all rounds, across n users\n",
    "    # is then put into a dataframe for roundwise stats required for plotting\n",
    "    \n",
    "    rounds = [i+ignore_first_n for i in range(rounds)]\n",
    "    df_index = 0\n",
    "    for rnd in rounds:\n",
    "        rnd -= ignore_first_n\n",
    "        if pre:\n",
    "            df.loc[df_index] = [\"Pre\", rnd+ignore_first_n, \n",
    "                                pre_avg[rnd], pre_std_dev[rnd], \n",
    "                                pre_mini[rnd], pre_maxi[rnd]]\n",
    "            df_index +=1\n",
    "        \n",
    "        if post:\n",
    "            df.loc[df_index] = [\"Post\", rnd+ignore_first_n, \n",
    "                                post_avg[rnd], post_std_dev[rnd], \n",
    "                                post_mini[rnd], post_maxi[rnd]]\n",
    "            df_index +=1    \n",
    "    return (df, rounds)\n",
    "\n",
    "\n",
    "def avg_round_stats(users, std_dev_fill = False, min_max_fill = False,\n",
    "                        loss = False, accuracy = False, pre = True, post = True,\n",
    "                        ignore_first_n = 0, save_as = None, final_values = False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    prints graphs based on per round data and optionally returns the final metric \n",
    "    values for them as well. Use save_as to save the graph plotted and can ignore_first_n\n",
    "    round data in the graphin\n",
    "    \"\"\"\n",
    "\n",
    "    if (loss == accuracy) or (std_dev_fill and min_max_fill):\n",
    "        print(\"Please select one from accuracy or loss and one or nonefrom std_dev_fill or min_max_fill\")\n",
    "        return None\n",
    "    # get the data for the prints ready\n",
    "    metric = \"Accuracy\"\n",
    "    if loss:\n",
    "        metric = \"Loss\"\n",
    "    \n",
    "    fill_type = None\n",
    "    if std_dev_fill:\n",
    "        fill_type = \"std_dev_fill\"\n",
    "    elif min_max_fill:\n",
    "        fill_type = \"min_max_fill\"\n",
    "    \n",
    "    \n",
    "    # data collection into df\n",
    "    df, rounds = roundwise_stats_df(users, \n",
    "                     ignore_first_n = ignore_first_n, \n",
    "                          loss = loss, \n",
    "                          accuracy = accuracy, \n",
    "                        post = post , pre = pre)\n",
    "    # plot here and then fill here\n",
    "    if pre:\n",
    "        if final_values:\n",
    "            print(f\"Final values for Pre-fit {metric}\")\n",
    "            finals = df[df[\"Position\"]==\"Pre\"].iloc[-1]\n",
    "            print(finals)\n",
    "\n",
    "        _plot_with_fill(df, x_axis = rounds,\n",
    "                        position = \"Pre\",\n",
    "                        metric = metric,\n",
    "                        color = \"r\",\n",
    "                        min_max_fill = min_max_fill, \n",
    "                        std_dev_fill = std_dev_fill)\n",
    "    \n",
    "    if post:\n",
    "        if final_values:\n",
    "            print(f\"Final values for Post-fit {metric}\")\n",
    "            finals = df[df[\"Position\"]==\"Post\"].iloc[-1]\n",
    "            print(finals,end=\"\\n\\n\")\n",
    "        _plot_with_fill(df, x_axis = rounds,\n",
    "                        position = \"Post\",\n",
    "                        metric = metric,\n",
    "                        color = \"b\",\n",
    "                        min_max_fill = min_max_fill, \n",
    "                        std_dev_fill = std_dev_fill)\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.xlabel(\"Rounds\")\n",
    "    plt.ylabel(f\"{metric}\")\n",
    "    plt.title(f\"Average {metric} per Round with fill type: {fill_type}\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if save_as:\n",
    "        plt.savefig(save_as)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### algorithm:\n",
    "df = read_file(\"../dataset/allUsers.lcl.csv\")\n",
    "# shuffle the records\n",
    "# df = df.sample(frac = 1)\n",
    "\n",
    "# using below line and not np.random.seed(SEED) as otherwise, that\n",
    "# line needs to be called everytime before shuffling the \n",
    "# dataframe cause it \"moves\"\n",
    "df = df.take(np.random.RandomState(seed=SEED).permutation(df.shape[0]))\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "averaging_methods = [Average.all,Average.std_dev,Average.weighted_avg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = '/cpu:0'\n",
    "ROUNDS = 32\n",
    "EPOCHS = 16 # 16 is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    averaging_methods = [Average.all]\n",
    "    \n",
    "    users_all, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_all, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method = Average.all,\n",
    "              averaging_post = True,\n",
    "              averaging_accuracy = True)\n",
    "    \n",
    "    users_all_2, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_all_2, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              \n",
    "              strat = \"personalised\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_accuracy = True)\n",
    "    \n",
    "    \n",
    "#     users, global_user = init_users(df) # return a dictionary of users with data\n",
    "    \n",
    "#     print(\"Global user training and validation\")\n",
    "#     global_user.train(epochs = EPOCHS*ROUNDS,\n",
    "#        verbose_fit = True,\n",
    "#        verbose_evaluate = True,\n",
    "#     )\n",
    "#     draw_graphs(global_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    averaging_methods = [Average.std_dev]\n",
    "    users_std_dev, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_std_dev, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method =  Average.std_dev,\n",
    "             averaging_post = True,\n",
    "             averaging_accuracy = True)\n",
    "    \n",
    "    users_std_dev_2, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_std_dev_2, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              \n",
    "              strat = \"personalised\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_accuracy = True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(DEVICE):\n",
    "    averaging_methods = [Average.weighted_avg]\n",
    "    \n",
    "    users_weighted_avg, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_weighted_avg, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              strat = \"central\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_method = Average.weighted_avg,\n",
    "             averaging_post = True,\n",
    "             averaging_accuracy = True)\n",
    "    \n",
    "    users_weighted_avg_2, global_user = init_users(df, averaging_methods, SEED) # return a dictionary of users with data\n",
    "    train_fed(users = users_weighted_avg_2, rounds = ROUNDS,\n",
    "              epochs = EPOCHS,\n",
    "              \n",
    "              strat = \"personalised\",\n",
    "              train_user_verbose = False,\n",
    "              train_user_verbose_evaluate = False,\n",
    "              train_user_verbose_fit = False,\n",
    "              averaging_post = True,\n",
    "              averaging_accuracy = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_first_n = 0\n",
    "final_values = True\n",
    "\n",
    "print(\"All\")\n",
    "\n",
    "# print(\"For p2p\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_all_2, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_all_2, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)\n",
    "print(\"For central\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_all, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_all, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_first_n = 0\n",
    "final_values = True\n",
    "\n",
    "print(\"Std deviation\")\n",
    "\n",
    "print(\"For p2p\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_std_dev_2, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_std_dev_2, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)\n",
    "print(\"For central\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_std_dev, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_std_dev, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_first_n = 0\n",
    "final_values = True\n",
    "\n",
    "print(\"Weighted average\")\n",
    "\n",
    "print(\"For p2p\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_weighted_avg_2, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_weighted_avg_2, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)\n",
    "print(\"For central\")\n",
    "\n",
    "\n",
    "df_avg_round_stats_acc = avg_round_stats(users_weighted_avg, \n",
    "                                         ignore_first_n = ignore_first_n, \n",
    "                                         min_max_fill = True, \n",
    "                                         accuracy = True,\n",
    "                                         final_values = final_values)\n",
    "df_avg_user_stats_acc = avg_user_stats(users_weighted_avg, \n",
    "                                       ignore_first_n = ignore_first_n, \n",
    "                                       min_max_fill = True, \n",
    "                                       accuracy = True,\n",
    "                                      final_values = final_values)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
