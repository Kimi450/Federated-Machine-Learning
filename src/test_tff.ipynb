{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from user import User\n",
    "from average import Average\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "from six.moves import range\n",
    "import six\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# import random\n",
    "# random.seed(SEED)\n",
    "# tf.set_random_seed(SEED)\n",
    "# could need to force keras to not use parallelism, see documentation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#@test {\"skip\": true}\n",
    "\n",
    "# NOTE: If you are running a Jupyter notebook, and installing a locally built\n",
    "# pip package, you may need to edit the following to point to the '.whl' file\n",
    "# on your local filesystem.\n",
    "\n",
    "# NOTE: The high-performance executor components used in this tutorial are not\n",
    "# yet included in the released pip package; you may need to compile from source.\n",
    "\n",
    "# NOTE: Jupyter requires a patch to asyncio.\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# NOTE: If the statement below fails, it means that you are\n",
    "# using an older version of TFF without the high-performance\n",
    "# executor stack. Call `tff.framework.set_default_executor()`\n",
    "# instead to use the default reference runtime.\n",
    "if six.PY3:\n",
    "    tff.framework.set_default_executor(tff.framework.create_local_executor())\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    \"\"\"\n",
    "    return 2d df after imputing with 0s\"\"\"\n",
    "\n",
    "    # read data\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # replace the question marks with NaN and then change data type to float 32\n",
    "    df.replace([\"?\"],np.nan, inplace = True)\n",
    "    df = df.astype(np.float32)\n",
    "\n",
    "    # imputation\n",
    "    df.fillna(0,inplace=True) # fill nulls with 0\n",
    "    return df\n",
    "\n",
    "def shuffle_df(df, seed = None):\n",
    "    \"\"\"Shuffle dataframe and reset the index\"\"\"\n",
    "    df = df.take(np.random.RandomState(seed=SEED).permutation(df.shape[0]))\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def acquire_user_data(df, for_user = None, seed = None):\n",
    "    \"\"\"\n",
    "    split the dataframe into train, validation and test splits based on the same seed\n",
    "    Empty dataframes if no data present\n",
    "    \"\"\"\n",
    "    # split into train, validation and test data using sklearn and return dfs for each\n",
    "    if for_user!=None:\n",
    "        df = df[df[\"User\"] == for_user]\n",
    "    if df.shape[0] == 0:\n",
    "        # if no data for the user, then return 9 empty dfs as per the api\n",
    "        # print(f\"Dataframe for user {user} is of shape {df.shape}, no data. Skipping...\")\n",
    "        df = pd.DataFrame()\n",
    "        return df, df\n",
    "    target = df[\"Class\"]\n",
    "\n",
    "    # drop the class and user identifier columns from data frame\n",
    "    df   = df.drop(df.columns[[0,1]], axis=1)\n",
    "    return df, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_users(df, averaging_methods, averaging_metric = \"accuracy\", seed = None):\n",
    "    \"\"\"\n",
    "    Requires the DF to contain a \"User\" column giving numeric identity to a user\n",
    "    0 to unique_user_count-1\n",
    "    \n",
    "    Averaging method is a list of methods out of which a random one is selected\n",
    "    \n",
    "    initialise users based on dataframe given and assign random averaging method\n",
    "    to them based on the list passed in.\n",
    "    returns a dictionary of users(key: user object) and a global user object\n",
    "    \"\"\"    \n",
    "    print(\"Initialising User instances...\")\n",
    "    users = dict()\n",
    "    num_users = df[\"User\"].nunique()\n",
    "\n",
    "    for user_id in range(num_users):\n",
    "        \n",
    "        user_df, target = acquire_user_data(df = df, for_user=user_id, seed = seed)\n",
    "        \n",
    "        if user_df.shape[0]==0:\n",
    "            print(f\"User {user_id} has no data, no instance created...\")\n",
    "            continue\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((user_df.values, target.values))\n",
    "        \n",
    "        users[user_id] = dataset        \n",
    "\n",
    "    print(f\"{len(users.keys())} User datasets created!\")\n",
    "    return users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create federated ClientData dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 500\n",
    "averaging_methods = [Average.all,Average.std_dev,Average.weighted_avg]\n",
    "\n",
    "\n",
    "df = read_file(\"../dataset/allUsers.lcl.csv\")\n",
    "df = shuffle_df(df, SEED)\n",
    "client_id_colname = 'Class' # the column that represents client IDNUM_CLIENTS = len(users)\n",
    "users= init_users(df = df, \n",
    "                        averaging_methods = averaging_methods, \n",
    "                        seed = SEED)\n",
    "client_ids = np.array(users.keys())\n",
    "client_ids = df[\"User\"].unique()\n",
    "\n",
    "train_client_ids = np.random.choice(client_ids, client_ids.size//2, replace=False).tolist()\n",
    "print(train_client_ids)\n",
    "# client_ids.sample(frac=0.5).tolist()\n",
    "test_client_ids = [x for x in client_ids if x not in train_client_ids]\n",
    "\n",
    "def create_tf_dataset_for_client_fn(client_id):\n",
    "    # a function which takes a client_id and returns a\n",
    "    # tf.data.Dataset for that client\n",
    "    client_data = df[df[client_id_colname] == client_id]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(client_data.to_dict('list'))\n",
    "#     dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)\n",
    "    dataset = dataset.repeat(NUM_EPOCHS).shuffle(\n",
    "          SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "train_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "        client_ids=train_client_ids,\n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "test_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "        client_ids=test_client_ids,\n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "example_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[0]\n",
    "    )\n",
    "print(type(example_dataset))\n",
    "example_element = iter(example_dataset).next()\n",
    "print(example_element)\n",
    "# <class 'tensorflow.python.data.ops.dataset_ops.RepeatDataset'>\n",
    "# {'age': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([37], dtype=int32)>, 'workclass': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Local-gov'], dtype=object)>, ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is before I started making HDF5 files and datasets from them\n",
    "Structure of the file:\n",
    "- examples\n",
    "    - userID\n",
    "        - features\n",
    "\n",
    "\n",
    "- https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/simulation/hdf5_client_data_test.py\n",
    "- https://github.com/tensorflow/federated/blob/v0.11.0/tensorflow_federated/python/simulation/hdf5_client_data.py\n",
    "- http://docs.h5py.org/en/stable/high/group.html#Group.create_dataset\n",
    "- https://stackoverflow.com/questions/55434004/create-a-custom-federated-data-set-in-tensorflow-federated\n",
    "- https://stackoverflow.com/questions/58965488/how-to-create-federated-dataset-from-a-csv-file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMNIST example from the website\n",
    "- https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "\n",
    "example_element = iter(example_dataset).next()\n",
    "\n",
    "print(example_element['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 500\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "    def element_fn(element):\n",
    "        return collections.OrderedDict([\n",
    "            ('x', tf.reshape(element['pixels'], [-1])),\n",
    "            ('y', tf.reshape(element['label'], [1])),\n",
    "        ])\n",
    "\n",
    "    return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(\n",
    "      SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "type(emnist_train)\n",
    "\n",
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(\n",
    "    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n",
    "\n",
    "sample_batch\n",
    "\n",
    "def make_federated_data(client_data, client_ids):\n",
    "    return [preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "          for x in client_ids]\n",
    "\n",
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "len(federated_train_data), federated_train_data[0]\n",
    "\n",
    "def create_compiled_keras_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          10, activation=tf.nn.softmax, kernel_initializer='zeros', input_shape=(784,))])\n",
    "\n",
    "    model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "def model_fn():\n",
    "    keras_model = create_compiled_keras_model()\n",
    "    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)\n",
    "\n",
    "\n",
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)\n",
    "str(iterative_process.initialize.type_signature)\n",
    "state = iterative_process.initialize()\n",
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))\n",
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
